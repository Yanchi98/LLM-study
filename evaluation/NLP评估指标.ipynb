{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU SCORE: 0.274941620352113\n"
     ]
    }
   ],
   "source": [
    "'''BLEU,翻译任务'''\n",
    "import nltk\n",
    "\n",
    "def calculate_bleu(reference, candidate):\n",
    "    reference = [reference.split()]\n",
    "    candidate = candidate.split()\n",
    "    smoothing_function = nltk.translate.bleu_score.SmoothingFunction()\n",
    "    bleu_score = nltk.translate.bleu_score.sentence_bleu(reference, candidate, smoothing_function=smoothing_function.method1)\n",
    "    return bleu_score\n",
    "\n",
    "reference_sentence = \"The cat is on the mat\"\n",
    "candidate_sentence = \"The cat is sitting on the mat\"\n",
    "\n",
    "bleu = calculate_bleu(reference_sentence, candidate_sentence)\n",
    "print(\"BLEU SCORE:\", bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 score: 0.9230769181065088\n",
      "ROUGE-2 score: 0.7272727223140496\n",
      "ROUGE-L score: 0.9230769181065088\n"
     ]
    }
   ],
   "source": [
    "'''Rouge 摘要任务'''\n",
    "from rouge import Rouge\n",
    "\n",
    "def calculate_rouge(reference, candidate):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(candidate, reference)\n",
    "    rouge_1 = scores[0]['rouge-1']['f']\n",
    "    rouge_2 = scores[0]['rouge-2']['f']\n",
    "    rouge_l = scores[0]['rouge-l']['f']\n",
    "    return rouge_1, rouge_2, rouge_l\n",
    "\n",
    "# 示例用法\n",
    "reference_summary = \"The cat is on the mat\"\n",
    "candidate_summary = \"The cat is sitting on the mat\"\n",
    "rouge_1, rouge_2, rouge_l = calculate_rouge(reference_summary, candidate_summary)\n",
    "print(\"ROUGE-1 score:\", rouge_1)\n",
    "print(\"ROUGE-2 score:\", rouge_2)\n",
    "print(\"ROUGE-L score:\", rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER score: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "'''Wer word Error Rate'''\n",
    "import jiwer\n",
    "\n",
    "def calculate_wer(reference, candidate):\n",
    "    wer = jiwer.wer(reference, candidate)\n",
    "    return wer\n",
    "\n",
    "# 示例用法\n",
    "reference_transcription = \"The cat is on the mat\"\n",
    "candidate_transcription = \"The cat is sitting on the mat\"\n",
    "wer = calculate_wer(reference_transcription, candidate_transcription)\n",
    "print(\"WER score:\", wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
